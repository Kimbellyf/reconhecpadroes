{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "evalue": "Error: Jupyter cannot be started. Error attempting to locate jupyter: Error: Module 'notebook' not installed.",
     "output_type": "error"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#análises de dados, \n",
    "#dividiremos os dados em conjuntos de treinamento e teste,\n",
    "#treinaremos o algoritmo, faremos previsões, e\n",
    "#finalmente avaliaremos o desempenho do algoritmo em nosso conjunto de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ler_csv(file, separador, encode, zebrado=False):\n",
    "    return pd.read_csv(file, sep=separador, encoding=encode, squeeze = zebrado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kimbelly\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3214: DtypeWarning: Columns (157) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if (yield from self.run_code(code, result)):\n"
     ]
    }
   ],
   "source": [
    "#df_ESC = ler_csv(\"../base/ESCOLAS.CSV\", '|', 'iso-8859-1', True)\n",
    "#df_PU_ESC= ler_csv(\"../base/ESCOLA_publicas.csv\", ',', 'iso-8859-1', True)\n",
    "#df_TS_ESC= ler_csv(\"../base/TS_ESCOLA.csv\", ',', 'iso-8859-1', True)\n",
    "#df_estados = ler_csv(\"../base/EsatosNomeUFRegiao.csv\", ',', 'iso-8859-1', True)\n",
    "df_all_base = ler_csv(\"./base/Base_Completa.csv\", ';', 'utf-8', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#datasetCensoMoreSabe = pd.read_csv(\"censo_saeb_join.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=df_all_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(73674, 326)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape  # para ver o número de linhas e colunas em nosso conjunto de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_PROVA_BRASIL</th>\n",
       "      <th>ID_UF</th>\n",
       "      <th>ID_MUNICIPIO</th>\n",
       "      <th>ID_ESCOLA</th>\n",
       "      <th>ID_DEPENDENCIA_ADM</th>\n",
       "      <th>ID_LOCALIZACAO</th>\n",
       "      <th>PC_FORMACAO_DOCENTE_INICIAL</th>\n",
       "      <th>PC_FORMACAO_DOCENTE_FINAL</th>\n",
       "      <th>PC_FORMACAO_DOCENTE_MEDIO</th>\n",
       "      <th>NIVEL_SOCIO_ECONOMICO</th>\n",
       "      <th>...</th>\n",
       "      <th>IN_ESP_EXCLUSIVA_EJA_MEDIO</th>\n",
       "      <th>IN_ESP_EXCLUSIVA_EJA_PROF</th>\n",
       "      <th>IN_COMUM_PROF</th>\n",
       "      <th>IN_ESP_EXCLUSIVA_PROF</th>\n",
       "      <th>cod</th>\n",
       "      <th>regiao</th>\n",
       "      <th>NM_UF</th>\n",
       "      <th>Capital</th>\n",
       "      <th>NM_UF_SIGLA</th>\n",
       "      <th>MEDIA_TOTAL_5EF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017</td>\n",
       "      <td>11</td>\n",
       "      <td>1100015</td>\n",
       "      <td>11024666</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>83.3</td>\n",
       "      <td>55.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Grupo 2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Norte</td>\n",
       "      <td>RondÃ´nia</td>\n",
       "      <td>Porto Velho</td>\n",
       "      <td>RO</td>\n",
       "      <td>224.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017</td>\n",
       "      <td>11</td>\n",
       "      <td>1100015</td>\n",
       "      <td>11024682</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>94.2</td>\n",
       "      <td>64.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Grupo 3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Norte</td>\n",
       "      <td>RondÃ´nia</td>\n",
       "      <td>Porto Velho</td>\n",
       "      <td>RO</td>\n",
       "      <td>256.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017</td>\n",
       "      <td>11</td>\n",
       "      <td>1100015</td>\n",
       "      <td>11024828</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>55.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Grupo 3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Norte</td>\n",
       "      <td>RondÃ´nia</td>\n",
       "      <td>Porto Velho</td>\n",
       "      <td>RO</td>\n",
       "      <td>202.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017</td>\n",
       "      <td>11</td>\n",
       "      <td>1100015</td>\n",
       "      <td>11024968</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.9</td>\n",
       "      <td>77.1</td>\n",
       "      <td>Grupo 3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Norte</td>\n",
       "      <td>RondÃ´nia</td>\n",
       "      <td>Porto Velho</td>\n",
       "      <td>RO</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017</td>\n",
       "      <td>11</td>\n",
       "      <td>1100015</td>\n",
       "      <td>11025077</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>55.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Norte</td>\n",
       "      <td>RondÃ´nia</td>\n",
       "      <td>Porto Velho</td>\n",
       "      <td>RO</td>\n",
       "      <td>201.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 326 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID_PROVA_BRASIL  ID_UF  ID_MUNICIPIO  ID_ESCOLA  ID_DEPENDENCIA_ADM  \\\n",
       "0             2017     11       1100015   11024666                   3   \n",
       "1             2017     11       1100015   11024682                   2   \n",
       "2             2017     11       1100015   11024828                   3   \n",
       "3             2017     11       1100015   11024968                   2   \n",
       "4             2017     11       1100015   11025077                   3   \n",
       "\n",
       "   ID_LOCALIZACAO  PC_FORMACAO_DOCENTE_INICIAL  PC_FORMACAO_DOCENTE_FINAL  \\\n",
       "0               2                         83.3                       55.6   \n",
       "1               1                         94.2                       64.1   \n",
       "2               1                        100.0                       55.6   \n",
       "3               1                          0.0                       48.9   \n",
       "4               1                        100.0                       55.6   \n",
       "\n",
       "   PC_FORMACAO_DOCENTE_MEDIO NIVEL_SOCIO_ECONOMICO  ...  \\\n",
       "0                        0.0               Grupo 2  ...   \n",
       "1                        0.0               Grupo 3  ...   \n",
       "2                        0.0               Grupo 3  ...   \n",
       "3                       77.1               Grupo 3  ...   \n",
       "4                        0.0                     0  ...   \n",
       "\n",
       "   IN_ESP_EXCLUSIVA_EJA_MEDIO  IN_ESP_EXCLUSIVA_EJA_PROF  IN_COMUM_PROF  \\\n",
       "0                         0.0                        0.0            0.0   \n",
       "1                         0.0                        0.0            0.0   \n",
       "2                         0.0                        0.0            0.0   \n",
       "3                         0.0                        0.0            0.0   \n",
       "4                         0.0                        0.0            0.0   \n",
       "\n",
       "   IN_ESP_EXCLUSIVA_PROF  cod  regiao      NM_UF      Capital  NM_UF_SIGLA  \\\n",
       "0                    0.0  1.0   Norte  RondÃ´nia  Porto Velho           RO   \n",
       "1                    0.0  1.0   Norte  RondÃ´nia  Porto Velho           RO   \n",
       "2                    0.0  1.0   Norte  RondÃ´nia  Porto Velho           RO   \n",
       "3                    0.0  1.0   Norte  RondÃ´nia  Porto Velho           RO   \n",
       "4                    0.0  1.0   Norte  RondÃ´nia  Porto Velho           RO   \n",
       "\n",
       "   MEDIA_TOTAL_5EF  \n",
       "0           224.05  \n",
       "1           256.25  \n",
       "2           202.24  \n",
       "3             0.00  \n",
       "4           201.00  \n",
       "\n",
       "[5 rows x 326 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset.columns\n",
    "#[x for x in dataset.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparando os dados\n",
    "#Nesta seção, dividiremos nossos dados em atributos e rótulos e, \n",
    "#em seguida, dividiremos os dados resultantes em conjuntos de treinamento e teste. \n",
    "#Ao fazer isso, podemos treinar nosso algoritmo em um conjunto de dados e testá-lo \n",
    "#em um conjunto de dados completamente diferente que o algoritmo ainda não viu. \n",
    "#Isso fornece uma visão mais precisa do desempenho real do seu algoritmo treinado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#na vdd é classe \n",
    "#dividir dados em atributos e rótulos\n",
    "#X = dataset.drop('CO_ENTIDADE', axis=1)\n",
    "X = dataset[[ 'IN_LABORATORIO_INFORMATICA','IN_BIBLIOTECA', 'IN_AGUA_FILTRADA', 'IN_ENERGIA_REDE_PUBLICA','IN_AGUA_INEXISTENTE','IN_ESGOTO_INEXISTENTE','IN_QUADRA_ESPORTES', 'IN_SALA_LEITURA','IN_BIBLIOTECA_SALA_LEITURA', 'IN_INTERNET']]\n",
    "\n",
    "\n",
    "dataset['rotulo'] = list(map(lambda x : 1 if x>300 else 0, dataset.loc[:,'MEDIA_TOTAL_5EF']))\n",
    "y = dataset['rotulo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_test_split método, que usaremos para dividir os dados aleatoriamente em conjuntos de treinamento e teste. \n",
    "#o test_size parâmetro especifica a proporção do conjunto de testes, que usamos \n",
    "#para dividir 20% dos dados no conjunto de testes e 80% para o treinamento.\n",
    "from sklearn.model_selection import train_test_split \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Depois que os dados foram divididos nos conjuntos de treinamento e teste, \n",
    "#a etapa final é treinar o algoritmo da árvore de decisão nesses dados e fazer previsões."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "classifier = DecisionTreeClassifier()\n",
    "classifier.fit(X_train, y_train)\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "classifier = DecisionTreeClassifier()\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agora que nosso classificador foi treinado, vamos fazer previsões sobre os dados do teste. \n",
    "#Para fazer previsões, o predictmétodo da DecisionTreeClassifierclasse é usado.\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Neste ponto, treinamos nosso algoritmo e fizemos algumas previsões. \n",
    "#Agora veremos quão preciso é o nosso algoritmo. \n",
    "#Para tarefas de classificação, algumas métricas comumente usadas são matriz de confusão , \n",
    "#precisão, recuperação e pontuação F1 . \n",
    "#Para nossa sorte, a metricsbiblioteca do Scikit = -Learn contém os métodos classification_reporte confusion_matrixque podem ser usados \n",
    "#para calcular essas métricas para nós:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[14712     0]\n",
      " [   23     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     14712\n",
      "           1       0.00      0.00      0.00        23\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     14735\n",
      "   macro avg       0.50      0.50      0.50     14735\n",
      "weighted avg       1.00      1.00      1.00     14735\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kimbelly\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
